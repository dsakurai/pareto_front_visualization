{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:32.940432Z",
     "start_time": "2023-08-01T01:12:23.739741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# TDA magic\n",
    "from gtda.mapper import (\n",
    "    CubicalCover,\n",
    "    make_mapper_pipeline,\n",
    "    plot_static_mapper_graph,\n",
    "    plot_interactive_mapper_graph\n",
    ")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_original = pd.read_csv(\"20230726_結果_サンプル.csv\")\n",
    "# objectives= ['f1', 'f2', 'f3', 'f4', 'f5']\n",
    "\n",
    "\n",
    "# minimize = [\n",
    "#     True, True, True, # Minimize\n",
    "#     False, False # Maximize\n",
    "# ]\n",
    "\n",
    "# print(df_original.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or generate some sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.330046</td>\n",
       "      <td>-0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>0.818116</td>\n",
       "      <td>0.428214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.867558</td>\n",
       "      <td>-0.977278</td>\n",
       "      <td>-2.503947</td>\n",
       "      <td>0.120481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>0.807893</td>\n",
       "      <td>0.602121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>-0.865190</td>\n",
       "      <td>-0.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.652768</td>\n",
       "      <td>2.018161</td>\n",
       "      <td>-0.259534</td>\n",
       "      <td>-0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.066968</td>\n",
       "      <td>2.736475</td>\n",
       "      <td>-0.584336</td>\n",
       "      <td>1.006808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-1.012997</td>\n",
       "      <td>0.271662</td>\n",
       "      <td>0.592039</td>\n",
       "      <td>-1.457199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.108997</td>\n",
       "      <td>-0.057259</td>\n",
       "      <td>2.011115</td>\n",
       "      <td>1.689858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.058931</td>\n",
       "      <td>-0.326528</td>\n",
       "      <td>0.199966</td>\n",
       "      <td>-1.224331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        f1        f2\n",
       "0     1.764052  0.400157  0.330046 -0.000480\n",
       "1     0.978738  2.240893  0.818116  0.428214\n",
       "2     1.867558 -0.977278 -2.503947  0.120481\n",
       "3     0.950088 -0.151357  0.807893  0.602121\n",
       "4    -0.103219  0.410599 -0.865190 -0.153320\n",
       "...        ...       ...       ...       ...\n",
       "9995  1.652768  2.018161 -0.259534 -0.000423\n",
       "9996  0.066968  2.736475 -0.584336  1.006808\n",
       "9997 -1.012997  0.271662  0.592039 -1.457199\n",
       "9998 -0.108997 -0.057259  2.011115  1.689858\n",
       "9999 -1.058931 -0.326528  0.199966 -1.224331\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian distributions in n-D\n",
    "\n",
    "design_variables = ['x0', 'x1']\n",
    "objectives = ['f1', 'f2']\n",
    "\n",
    "minimize = [True] * len(objectives)\n",
    "\n",
    "size = 10000\n",
    "\n",
    "\n",
    "samples_design_variables = np.random.multivariate_normal(\n",
    "    mean=[0.0] * len(design_variables),\n",
    "    cov=np.eye(len(design_variables)), # independent distributions (i.e. eye, aka identity matrix)\n",
    "    size=size)\n",
    "\n",
    "samples_objectives = np.random.multivariate_normal(\n",
    "    mean=[0.0] * len(objectives),\n",
    "    cov=np.eye(len(objectives)), # independent distributions (i.e. eye, aka identity matrix)\n",
    "    size=size)\n",
    "\n",
    "df_design_variables = pd.DataFrame(samples_design_variables, columns= design_variables)\n",
    "df_objectives       = pd.DataFrame(samples_objectives,       columns= objectives)\n",
    "\n",
    "df_original = df_design_variables.join(df_objectives)\n",
    "\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and invert objectives\n",
    "# Normalization is done because we take the weighted sum of the multiple objectives to build a single objective function,\n",
    "# which will be passed to the mapper as the single filter function.\n",
    "# Inversion is done so that everything becomes a minimization problem.\n",
    "\n",
    "df_objectives_normalized = df_original[objectives]\n",
    "\n",
    "# Normalize\n",
    "df_objectives_normalized = (df_objectives_normalized - df_objectives_normalized.min()) / (df_objectives_normalized.max() - df_objectives_normalized.min())\n",
    "\n",
    "# Invert some rows\n",
    "for column, column_name in enumerate(df_objectives_normalized):\n",
    "    if not minimize[column]: # maximize\n",
    "        df_objectives_normalized[column_name] = 1.0 - df_objectives_normalized[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pareto(df_objectives: pd.DataFrame):\n",
    "\n",
    "    scores = df_objectives.values\n",
    "    num_points = scores.shape[0]\n",
    "\n",
    "    pareto_front = np.ones(num_points, dtype=bool)\n",
    "\n",
    "    for i, i_objectives in enumerate(scores):\n",
    "        for j, j_objectives in enumerate(scores):\n",
    "            if i == j: continue\n",
    "\n",
    "            #  not dominated                     and j dominates\n",
    "            if all(i_objectives >= j_objectives) and any(i_objectives > j_objectives):\n",
    "                pareto_front[i] = False\n",
    "                break # i is not in Pareto front\n",
    "    return pareto_front\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_original_objectives' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select Pareto fronts only; we also reset the index for simplicity\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This is because Giotto-tda's mapper graph (actually igraph.Graph) unfortunately does not take into account pandas' index row.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# (It uses iloc as the row IDs.)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# In other words, we match the pandas' built-in index with iloc so that we don't shoot our own foot.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask_pareto(\u001b[43mdf_original_objectives\u001b[49m)\n\u001b[1;32m      8\u001b[0m df_pareto            \u001b[38;5;241m=\u001b[39m df_original[mask]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m df_pareto_objectives \u001b[38;5;241m=\u001b[39m df_objectives_normalized[mask]\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_original_objectives' is not defined"
     ]
    }
   ],
   "source": [
    "# Select Pareto fronts only; we also reset the index for simplicity\n",
    "# This is because Giotto-tda's mapper graph (actually igraph.Graph) unfortunately does not take into account pandas' index row.\n",
    "# (It uses iloc as the row IDs.)\n",
    "# In other words, we match the pandas' built-in index with iloc so that we don't shoot our own foot.\n",
    "\n",
    "mask = mask_pareto(df_objectives_normalized)\n",
    "\n",
    "df_pareto            = df_original[mask].reset_index(drop=True)\n",
    "df_pareto_objectives = df_objectives_normalized[mask].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:34.587401Z",
     "start_time": "2023-08-01T01:12:32.941339Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "        df_pareto_objectives\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up mapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:34.643827Z",
     "start_time": "2023-08-01T01:12:34.643349Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter_func = np.mean\n",
    "# color_data  = filter_func(df.values, axis=1)\n",
    "\n",
    "num_objectives = len(objectives)\n",
    "\n",
    "# Weights to be used for weighted sum of the objective functions\n",
    "weights = [1.0 / num_objectives] * num_objectives\n",
    "\n",
    "# This is the filter function\n",
    "def weighted_sum(array, axis=1):\n",
    "    global weights\n",
    "    return np.dot(array, weights) # dot product (weighted sum)\n",
    "\n",
    "# Initialise pipeline\n",
    "pipe = make_mapper_pipeline(\n",
    "    filter_func=FunctionTransformer( # this transforms an ordinary Python function into a filter function.\n",
    "        weighted_sum  # actual filter function\n",
    "    ),\n",
    "    cover=CubicalCover( # Define cover for mapper\n",
    "        n_intervals=10,\n",
    "        overlap_frac=0.45),\n",
    "    clusterer=DBSCAN(),\n",
    "    verbose=False,\n",
    "    n_jobs=1, # parallelism for the clustering step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pipe.fit_transform(df_pareto_objectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as the color in the plot\n",
    "color_data  = weighted_sum(df_pareto_objectives, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:35.657697Z",
     "start_time": "2023-08-01T01:12:34.643528Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_static_mapper_graph(\n",
    "    pipe, df_pareto_objectives, color_data=color_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With vertical axis as the cluster level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:37.236062Z",
     "start_time": "2023-08-01T01:12:35.659728Z"
    }
   },
   "outputs": [],
   "source": [
    "import igraph\n",
    "import networkx as nx\n",
    "\n",
    "def reset_y(graph: nx.Graph, pos, ys): # graph is the networkx graph\n",
    "    # Apply constraint to y-coordinates\n",
    "    for node in graph.nodes:\n",
    "        pos[node][1] = ys[node]\n",
    "\n",
    "\n",
    "def custom_layout(graph: igraph.Graph, dim):\n",
    "\n",
    "    ys = { node.index:\n",
    "            node.attributes()['pullback_set_label']\n",
    "            for node in graph.vs\n",
    "    }\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for node in graph.vs:\n",
    "        G.add_node(node.index)\n",
    "    for edge in graph.get_edgelist():\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    for i in range(10): # improve spring layout by iteration\n",
    "        # Generate the spring layout positions\n",
    "        pos = nx.spring_layout(G,\n",
    "                               pos=pos\n",
    "                               , k=3.0 # specify the optimal distance between points. Comment out this line to use the default parameter\n",
    "                              )\n",
    "        reset_y(G, pos, ys)\n",
    "    \n",
    "    return igraph.Layout(\n",
    "        [\n",
    "            pos[node]\n",
    "            for node in G.nodes\n",
    "        ]\n",
    "    )\n",
    "\n",
    "plot_static_mapper_graph(\n",
    "    pipe, df_pareto_objectives, color_data=color_data,\n",
    "    layout=custom_layout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Intervention\n",
    "\n",
    "Find a local minimum in the mapper graph above and set its node as `mapper_node_id` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T01:12:37.241375Z",
     "start_time": "2023-08-01T01:12:37.235834Z"
    }
   },
   "outputs": [],
   "source": [
    "# mapper_node_id = 8\n",
    "mapper_node_id = 0\n",
    "\n",
    "# The row IDs in the dataframe. Warning: we don't use the original ID for this, but merely the ID of each Pareto front vertex.\n",
    "df_row_ids = graph.vs[mapper_node_id].attributes()['node_elements']\n",
    "df_row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the contents of the mapper nodes like this:\n",
    "\n",
    "for v in graph.vs:\n",
    "    print(\"mapper node\", f\"{v.index}:\", v.attributes()['node_elements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "knee = df_row_ids\n",
    "\n",
    "print(\"Red points: good points (points around the knee point)\")\n",
    "\n",
    "def color(id):\n",
    "    global knee\n",
    "    if id in knee:\n",
    "        return 'red'\n",
    "    return 'blue'\n",
    "    \n",
    "\n",
    "dic = {v: color(v) for v in range(df_objectives.index.max() + 1) }\n",
    "\n",
    "# Attach marker color in the dataframe\n",
    "df_colored = df_pareto_objectives.copy(deep=False)\n",
    "\n",
    "df_colored['index'] = df_colored.index # What we actually want to do is just to create a row with the name 'index'\n",
    "\n",
    "df_colored['color'] = df_colored['index'].map(dic)\n",
    "\n",
    "dimensions = []\n",
    "for each in df_pareto_objectives:\n",
    "    dimensions.append(\n",
    "        dict(\n",
    "            label = each,\n",
    "            values = df_pareto_objectives[each]\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=go.Splom(\n",
    "                dimensions=dimensions,\n",
    "                marker=dict(color=df_colored['color'],\n",
    "                            showscale=False, # colors encode categorical variables\n",
    "                           ),\n",
    "                text=df_colored['index'].map(lambda id: f'id in df: {id}')\n",
    "                ))\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200\n",
    ")\n",
    "\n",
    "for i in range(len(fig.data)):\n",
    "    fig.data[i].unselected = dict(\n",
    "        marker=dict(\n",
    "            color='black',  # unselected points will be black\n",
    "            opacity=0.3  # with this opacity\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pareto.iloc[knee]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
